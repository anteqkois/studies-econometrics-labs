{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawozdanie z cw.2 Antoni Kois gr.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openpyxl seaborn scikit-learn statsmodels\n",
    "import pandas as pd\n",
    "\n",
    "# Wczytanie danych z pliku\n",
    "df = pd.read_excel('../cw1/dane_przekrojowe_przykład.xlsx')\n",
    "\n",
    "# Podstawowe statystyki opisowe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1. Przygotowanie danych\n",
    "\n",
    "### 1.1\n",
    "Na podstawie współczynników zmienności i współczynników korelacji ocenić, czy któreś ze\n",
    "zmiennych (wszystkich dostępnych) powinny zostać wyeliminowane przed przystąpieniem do\n",
    "budowy modelu ekonometrycznego.\n",
    "\n",
    "### 1.2\n",
    "Zmodyfikować dostępny zbiór danych (rozważyć przekształcenia zmiennych, eliminację pewnych\n",
    "obserwacji).\n",
    "\n",
    "### 1.3\n",
    "Dokonać podziału zbioru danych na zbiór uczący (90% obserwacji) i testowy (10% obserwacji).\n",
    "Porównać statystyki na zbiorze uczącym i testowym. W jakim celu wykonywany jest ten podział? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import variation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Obliczenie współczynników zmienności\n",
    "num_cols = ['year', 'price', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "cv = df[num_cols].apply(lambda x: variation(x, nan_policy='omit'))\n",
    "print(\"\\nWspółczynniki zmienności dla naszego zbioru:\")\n",
    "print(cv)\n",
    "\n",
    "# Obliczenie macierzy korelacji aby sprawdzić jak łątwiej sprawdzić jak one wyglądają\n",
    "correlation_matrix = df[num_cols].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Macierz korelacji\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwanie obserwacji odstających na podstawie ceny (5 i 95 percentyl)\n",
    "lower, upper = df['price'].quantile([0.05, 0.95])\n",
    "df = df[(df['price'] >= lower) & (df['price'] <= upper)]\n",
    "\n",
    "# Usunięcie obserwacji, gdzie engineSize = 0, ponieważ jest to prawdopodobnie zastąpienie wartości NaN\n",
    "df = df[df['engineSize'] > 0]\n",
    "\n",
    "# Dodanie nowej kolumny - wiek samochodu. Gdyż poprostu dla roku współczynnik zmienności jest mały i bez senus jest go porównywać\n",
    "df['car_age'] = 2025 - df['year']\n",
    "df.drop(columns=['year'], inplace=True)  # Usunięcie kolumny 'year', nie jest już nam potrzebna\n",
    "\n",
    "# Usunięcie zmiennej 'mileage' (zbyt duża korelacja z rokiem, więc zostawiamy tylko jedną zmienną objaśniającą z tych dwóch)\n",
    "df.drop(columns=['mileage'], inplace=True)\n",
    "\n",
    "# Usunięcie wierszy, gdzie fuelType = Hybrid, gdyż wyraźnie widać, że tych aut ilościowo jest sporo mniej\n",
    "df = df[df['fuelType'] != 'Hybrid']\n",
    "\n",
    "# Usunięcie kolumny 'model', gdyż jest zmienną kategoryczną i ma zbyt wiele różnych wartości. Albo można \"model\" połączyć w mniejsze grupy i wtedy zmienić na faktory\n",
    "df.drop(columns=['model'], inplace=True)\n",
    "\n",
    "# Konwersja zmiennych kategorycznych na numeryczne (faktory)\n",
    "df = pd.get_dummies(df, columns=['transmission', 'fuelType'], drop_first=True)\n",
    "\n",
    "# Ponowne Sprawdzenie współczynników zmienności\n",
    "num_cols = ['price', 'tax', 'mpg', 'engineSize', 'car_age']\n",
    "cv = df[num_cols].apply(lambda x: variation(x, nan_policy='omit'))\n",
    "print(\"\\nWspółczynniki zmienności:\")\n",
    "print(cv)\n",
    "\n",
    "# sprawdzenie czy nie ma kolumn kategorycznych\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja bool na int, ponieważ metoda OLS nie przyjmuje typu boolean\n",
    "df[df.select_dtypes(['bool']).columns] = df.select_dtypes(['bool']).astype(int)\n",
    "\n",
    "# Podział na zbiór uczący i testowy\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Porównanie statystyk zbiorów\n",
    "print(\"\\nStatystyki zbioru uczącego:\")\n",
    "print(train_df.describe())\n",
    "print(\"\\nStatystyki zbioru testowego:\")\n",
    "print(test_df.describe())\n",
    "\n",
    "\n",
    "# Budowa modelu ekonometrycznego\n",
    "X_train = train_df.drop(columns=['price'])\n",
    "X_train[X_train.select_dtypes(['bool']).columns] = X_train.select_dtypes(['bool']).astype(int)  # Konwersja bool na int\n",
    "y_train = train_df['price']\n",
    "X_train = sm.add_constant(X_train)  # Dodanie stałej do modelu, w R funckja lm jest dodawan pod spodem w trakcie\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Podsumowanie modelu\n",
    "print(model.summary())\n",
    "\n",
    "# Przetestowanie na danych testowych\n",
    "X_test = test_df.drop(columns=['price'])\n",
    "y_test = test_df['price']\n",
    "X_test = sm.add_constant(X_test)  # Dodanie stałej\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Średni błąd bezwzględny - Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Średni błąd kwadratowy - Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na model uczący i uczony jest po to, by móc sprawdzić czy nasz model faktycznie działa odpowiednio, a do tego potrzebujemy danych, które model jeszcze \"nie widział\", gdyż istnieje ryzyko, że model działa znakomicie, ale tylko na danych które zna.\n",
    "\n",
    "Po przeprowadzonym teście wynika, że średnio model myli się o 2458.84 £ w cenie.\n",
    "MSE jest bardziej wrażliwy na duże błędy (przez podnoszenie do kwadratu), więc wysokie wartości mogą sugerować, że niektóre przewidywania są znacząco nietrafione.\n",
    "R² (współczynnik determinacji) wynosi 0.827, co oznacza, że model wyjaśnia 82,7% wariancji cen samochodów, jest to dość spora ilość i wskazuje początkowo iż nasz model jest dobry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Budowa i weryfikacja modelu ekonometrycznego (na zbiorze uczącym)\n",
    "\n",
    "\n",
    "### 2.1\n",
    "Za pomocą MNK oszacować parametry modelu, w którym zmienną objaśnianą (Y) będzie cena, a zmiennymi objaśniającymi (Xi) wszystkie zmienne, które zostały wybrane w zadaniu 1.\n",
    "\n",
    "### 2.2\n",
    "Zapisać reszty modelu i wykonać kilka różnych testów normalności rozkładu reszt. Podać nazwy wykorzystywanych testów, ich hipotezy oraz interpretację wyników. Do czego potrzebne jest założenie o rozkładzie normalnym reszt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model.resid\n",
    "\n",
    "# Test Shapiro-Wilka\n",
    "# H0: Reszty mają rozkład normalny.\n",
    "# H1: Reszty nie mają rozkładu normalnego.\n",
    "from scipy.stats import shapiro\n",
    "stat, p_value = shapiro(residuals)\n",
    "print(f\"Shapiro-Wilk test: stat={stat}, p={p_value}\")\n",
    "\n",
    "\n",
    "# Test Kołmogorowa-Smirnowa\n",
    "# H0: Reszty mają rozkład normalny.\n",
    "# H1: Reszty nie mają rozkładu normalnego.\n",
    "from scipy.stats import kstest\n",
    "stat, p_value = kstest(residuals, 'norm', args=(residuals.mean(), residuals.std()))\n",
    "print(f\"Kołmogorow-Smirnow test: stat={stat}, p={p_value}\")\n",
    "\n",
    "# Test Jarque-Bera\n",
    "# H0: Reszty mają rozkład normalny.\n",
    "# H1: Reszty nie mają rozkładu normalnego.\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "stat, p_value, _, _ = jarque_bera(residuals)\n",
    "print(f\"Jarque-Bera test: stat={stat}, p={p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli wartość p w testach jest mniejsza niż 0.05, odrzucamy hipotezę o normalności reszt, co oznacza, że model może nie spełniać jednego z założeń MNK.\n",
    "Normalność reszt jest istotnym założeniem modeli ekonometrycznych, ponieważ wpływa na jakości predykcji modelu.\n",
    "\n",
    "Widzę, po wynikach, iż odrzucają one H0 mówiące o normalności. Jednak podejrzewam, że jest to błędna decyzja spowodowana prawdopodobnie zbyt dużą próbką danych. Dlatego ponawiam testy na losowo wybranych próbkach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram reszt, by sprawdzić wizualnie czy reszty wyglądają na rozkład normalny\n",
    "sns.histplot(residuals, kde=True, bins=30, stat=\"density\", color=\"blue\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sm.qqplot(residuals, line='s')\n",
    "plt.title(\"Wykres Q-Q dla reszt modelu\")\n",
    "plt.show()\n",
    "\n",
    "sample_residuals = np.random.choice(residuals, 500, replace=False)  # Próbka 500 reszt\n",
    "\n",
    "shapiro_test = shapiro(sample_residuals)\n",
    "print(f\"Shapiro-Wilk (próbka): stat={shapiro_test.statistic}, p={shapiro_test.pvalue}\")\n",
    "\n",
    "stat, p_value = kstest(sample_residuals, 'norm', args=(sample_residuals.mean(), sample_residuals.std()))\n",
    "print(f\"Kołmogorow-Smirnow test: stat={stat}, p={p_value}\")\n",
    "\n",
    "stat, p_value, _, _ = jarque_bera(sample_residuals)\n",
    "print(f\"Jarque-Bera test: stat={stat}, p={p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz na podstawie testów można potwierdzić, że reszty mają rozkład normalny\n",
    "\n",
    "### 2.3\n",
    "Wybrać ostateczny podzbiór zmiennych objaśniających (na 2 sposoby):\n",
    "\n",
    "- Wykorzystać w tym celu metodę krokową wsteczną (bazującą na teście istotności t-studenta). Przedstawić krótko ideę tej metody.\n",
    "\n",
    "W tej metodzie zaczynamy od pełnego modelu (wszystkie zmienne) i usuwamy najmniej istotne (te z największym p-value w teście t-Studenta), aż zostaną tylko istotne zmienne.\n",
    "Jeśli p-value zmiennej w teście t-Studenta jest większe niż 0.05, oznacza to, że zmienna nie jest istotna i powinna zostać usunięta.\n",
    "\n",
    "\n",
    "- Wykorzystać kryteria informacyjne AIC, BIC.\n",
    "\n",
    "Metoda opiera się na minimalizacji AIC i BIC. W skrócie: im niższe AIC/BIC, tym lepszy model.\n",
    "Wybieramy kolumnę do usunięcia na podstawie p-value.\n",
    "Jeśli AIC/BIC się poprawiły (zmniejszyły), zostawiamy zmienną usuniętą i kontynuujemy proces.\n",
    "Jeśli AIC/BIC się pogorszyły, cofamy usunięcie i testujemy inną zmienną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzamy p-value dla każdej zmiennej w naszym dotychczaswoym modelu\n",
    "print(model.pvalues)\n",
    "\n",
    "# Widzę, że największe p-value ma transmission_Semi-Auto więc je usuwam i buduję model ponownie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_2_3_a = X_train.drop(columns=['transmission_Semi-Auto'])\n",
    "model = sm.OLS(y_train, X_train_2_3_a).fit()\n",
    "\n",
    "# Sprawdzamy nowe p-value i ponownie kasuję tą kolumnę z najwięksyzm p-value\n",
    "print(model.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_3_a = X_train_2_3_a.drop(columns=['fuelType_Petrol'])\n",
    "model = sm.OLS(y_train, X_train_2_3_a).fit()\n",
    "print(model.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_3_a = X_train_2_3_a.drop(columns=['transmission_Manual'])\n",
    "model = sm.OLS(y_train, X_train_2_3_a).fit()\n",
    "print(model.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na tym etapie sądzę, że ten podzbiór zmiennychh opisujących będzie wystarczający:\n",
    "- tax\n",
    "- mpg\n",
    "- engineSize\n",
    "- car_age\n",
    "\n",
    "Teraz przechodzę do drugiej metody AIC, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                     0.000000e+00\n",
      "tax                       1.094083e-37\n",
      "mpg                       0.000000e+00\n",
      "engineSize                0.000000e+00\n",
      "car_age                   0.000000e+00\n",
      "transmission_Manual       2.870374e-73\n",
      "transmission_Semi-Auto    5.895875e-01\n",
      "fuelType_Petrol           2.493727e-26\n",
      "dtype: float64\n",
      "AIC: 163282.64955068944, BIC: 163339.10892881386\n"
     ]
    }
   ],
   "source": [
    "# Przywracamy pierwotny model\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "print(model.pvalues)\n",
    "# Sprawdzamy początkowe wartości AIC i BIC\n",
    "print(f\"AIC: {model.aic}, BIC: {model.bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                   0.000000e+00\n",
      "tax                     1.053649e-37\n",
      "mpg                     0.000000e+00\n",
      "engineSize              0.000000e+00\n",
      "car_age                 0.000000e+00\n",
      "transmission_Manual    2.967069e-102\n",
      "fuelType_Petrol         9.033157e-27\n",
      "dtype: float64\n",
      "AIC: 163280.9408280782, BIC: 163330.34278393706\n"
     ]
    }
   ],
   "source": [
    "X_train_2_3_b = X_train.drop(columns=['transmission_Semi-Auto'])\n",
    "model = sm.OLS(y_train, X_train_2_3_b).fit()\n",
    "\n",
    "# Sprawdzamy nowe p-value i ponownie kasuję tą kolumnę z najwięksyzm p-value\n",
    "print(model.pvalues)\n",
    "print(f\"AIC: {model.aic}, BIC: {model.bic}\")\n",
    "\n",
    "# AIC i BIC zmieniły się lekko w odpowiednią stronę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                   0.000000e+00\n",
      "tax                     1.838814e-30\n",
      "mpg                     0.000000e+00\n",
      "engineSize              0.000000e+00\n",
      "car_age                 0.000000e+00\n",
      "transmission_Manual    5.611715e-104\n",
      "dtype: float64\n",
      "AIC: 163393.76775864937, BIC: 163436.11229224267\n"
     ]
    }
   ],
   "source": [
    "X_train_2_3_b = X_train_2_3_b.drop(columns=['fuelType_Petrol'])\n",
    "model = sm.OLS(y_train, X_train_2_3_b).fit()\n",
    "\n",
    "print(model.pvalues)\n",
    "print(f\"AIC: {model.aic}, BIC: {model.bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const              0.000000e+00\n",
      "tax                2.892782e-31\n",
      "mpg                0.000000e+00\n",
      "engineSize         0.000000e+00\n",
      "car_age            0.000000e+00\n",
      "fuelType_Petrol    1.701652e-28\n",
      "dtype: float64\n",
      "AIC: 163740.30689844518, BIC: 163782.6514320385\n"
     ]
    }
   ],
   "source": [
    "# Wyniki zmieniły się na niekorzyśc więc przywracamy kolumnę i usuwamy inną\n",
    "X_train_2_3_b['fuelType_Petrol'] = X_train['fuelType_Petrol']\n",
    "\n",
    "X_train_2_3_b = X_train_2_3_b.drop(columns=['transmission_Manual'])\n",
    "model = sm.OLS(y_train, X_train_2_3_b).fit()\n",
    "\n",
    "print(model.pvalues)\n",
    "print(f\"AIC: {model.aic}, BIC: {model.bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                  0.000000e+00\n",
      "mpg                    0.000000e+00\n",
      "engineSize             0.000000e+00\n",
      "car_age                0.000000e+00\n",
      "fuelType_Petrol        1.672533e-19\n",
      "transmission_Manual    7.507210e-96\n",
      "dtype: float64\n",
      "AIC: 163443.80388211738, BIC: 163486.1484157107\n"
     ]
    }
   ],
   "source": [
    "# Wyniki zbów zmieniły się na niekorzyśc więc przywracamy kolumnę i usuwamy inną\n",
    "X_train_2_3_b['transmission_Manual'] = X_train['transmission_Manual']\n",
    "\n",
    "X_train_2_3_b = X_train_2_3_b.drop(columns=['tax'])\n",
    "model = sm.OLS(y_train, X_train_2_3_b).fit()\n",
    "\n",
    "print(model.pvalues)\n",
    "print(f\"AIC: {model.aic}, BIC: {model.bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki na korzyść, usuwaliśmy już kolumny z największymi p-value, reszta ma sporo mniejsza wartości, więc to będzie nasz wynikowy zbiór zmiennych opisujących\n",
    "- mpg\n",
    "- engineSize\n",
    "- car_age\n",
    "- fuelType_Petrol\n",
    "- transmission_Manual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
